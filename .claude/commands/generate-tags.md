# Generate Article Tags Command

**Date:** 2025-01-03 | **Version:** 1.0

This command analyzes article content and automatically generates appropriate Qiita tags based on the technical topics, technologies, and themes discussed.

## Usage

- `/generate-tags` - Interactive mode: select series and articles
- `/generate-tags <seriesName>` - Generate tags for all articles in series
- `/generate-tags <seriesName> <articleName>` - Generate tags for specific article

## Features

- AI-powered content analysis
- Qiita tag compatibility validation
- Technology stack detection
- Topic and theme identification
- Japanese/English tag normalization
- Maximum 5 tags per article (Qiita limit)

## Process Flow

1. **Content Analysis**: Read article markdown content
2. **Technology Detection**: Identify programming languages, frameworks, tools
3. **Theme Analysis**: Extract main topics and concepts
4. **Tag Generation**: Create relevant, searchable tags
5. **Validation**: Check against Qiita's tag system
6. **Application**: Update article metadata with generated tags

---

## Implementation

```python
import os
import re
import json
from pathlib import Path
from typing import List, Dict, Set

# Common technology keywords and their Qiita tags
TECH_TAG_MAPPING = {
    # Programming Languages
    'python': 'Python',
    'javascript': 'JavaScript', 
    'typescript': 'TypeScript',
    'java': 'Java',
    'go': 'Go',
    'rust': 'Rust',
    'php': 'PHP',
    'ruby': 'Ruby',
    'c++': 'C++',
    'c#': 'C#',
    
    # Frameworks & Libraries
    'react': 'React',
    'vue': 'Vue.js',
    'angular': 'Angular',
    'django': 'Django',
    'flask': 'Flask',
    'express': 'Express',
    'spring': 'Spring',
    'laravel': 'Laravel',
    'rails': 'Rails',
    
    # Cloud & Infrastructure
    'aws': 'AWS',
    'azure': 'Azure',
    'gcp': 'GoogleCloud',
    'docker': 'Docker',
    'kubernetes': 'kubernetes',
    'terraform': 'Terraform',
    'ansible': 'Ansible',
    
    # Databases
    'mysql': 'MySQL',
    'postgresql': 'PostgreSQL',
    'mongodb': 'MongoDB',
    'redis': 'Redis',
    'elasticsearch': 'Elasticsearch',
    
    # AI/ML
    'ai': 'AI',
    'machine learning': 'MachineLearning',
    'deep learning': 'DeepLearning',
    'tensorflow': 'TensorFlow',
    'pytorch': 'PyTorch',
    'openai': 'OpenAI',
    'gpt': 'ChatGPT',
    'claude': 'Claude',
    
    # Architecture & Concepts
    'microservices': 'ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹',
    'serverless': 'ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹',
    'faas': 'FaaS',
    'iaas': 'IaaS',
    'saas': 'SaaS',
    'paas': 'PaaS',
    'api': 'API',
    'rest': 'REST',
    'graphql': 'GraphQL',
    'cdn': 'CDN',
    
    # Japanese Business/Tech Terms
    'dx': 'DX',
    'ãƒ‡ã‚¸ã‚¿ãƒ«å¤‰é©': 'DX',
    'ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢': 'ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢',
    'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°': 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°',
    'ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£': 'ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£',
    'ã‚¤ãƒ³ãƒ•ãƒ©': 'ã‚¤ãƒ³ãƒ•ãƒ©',
    'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£': 'ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£',
    'ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹': 'ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹',
}

def analyze_article_content(file_path: str) -> Dict[str, any]:
    """Analyze article content and extract key information"""
    
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Extract title
    title_match = re.search(r'^# (.+)', content, re.MULTILINE)
    title = title_match.group(1) if title_match else "No title"
    
    # Convert to lowercase for analysis
    content_lower = content.lower()
    title_lower = title.lower()
    
    # Count word frequencies
    word_counts = {}
    
    # Extract technical terms
    tech_terms = set()
    for keyword, tag in TECH_TAG_MAPPING.items():
        if keyword.lower() in content_lower or keyword.lower() in title_lower:
            tech_terms.add(tag)
    
    # Extract code blocks to identify languages
    code_blocks = re.findall(r'```(\w+)', content)
    for lang in code_blocks:
        if lang.lower() in TECH_TAG_MAPPING:
            tech_terms.add(TECH_TAG_MAPPING[lang.lower()])
    
    # Analyze content themes
    themes = set()
    
    # Infrastructure themes
    if any(term in content_lower for term in ['ã‚µãƒ¼ãƒãƒ¼', 'ã‚¤ãƒ³ãƒ•ãƒ©', 'ã‚¯ãƒ©ã‚¦ãƒ‰', 'aws', 'azure', 'gcp']):
        themes.add('ã‚¤ãƒ³ãƒ•ãƒ©')
    
    # AI/ML themes  
    if any(term in content_lower for term in ['ai', 'äººå·¥çŸ¥èƒ½', 'æ©Ÿæ¢°å­¦ç¿’', 'chatgpt', 'openai']):
        themes.add('AI')
    
    # Architecture themes
    if any(term in content_lower for term in ['ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£', 'ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹', 'api', 'è¨­è¨ˆ']):
        themes.add('ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£')
    
    # Business/Strategy themes
    if any(term in content_lower for term in ['æˆ¦ç•¥', 'çµŒå–¶', 'ãƒ“ã‚¸ãƒã‚¹', 'æŠ•è³‡', 'roi']):
        themes.add('ãƒ“ã‚¸ãƒã‚¹')
    
    # Performance themes
    if any(term in content_lower for term in ['ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹', 'æ€§èƒ½', 'æœ€é©åŒ–', 'ã‚³ã‚¹ãƒˆ']):
        themes.add('ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹')
    
    return {
        'title': title,
        'tech_terms': list(tech_terms),
        'themes': list(themes),
        'content_length': len(content),
        'code_languages': list(set(code_blocks))
    }

def generate_tags(analysis: Dict[str, any], max_tags: int = 5) -> List[str]:
    """Generate appropriate tags based on analysis"""
    
    tags = []
    
    # Add most relevant tech terms (max 2-3)
    tech_terms = analysis.get('tech_terms', [])
    tags.extend(tech_terms[:3])
    
    # Add themes (max 2)
    themes = analysis.get('themes', [])
    tags.extend(themes[:2])
    
    # Add general tags if needed
    if len(tags) < max_tags:
        # Add generic programming tag if code is present
        if analysis.get('code_languages'):
            if 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°' not in tags:
                tags.append('ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°')
        
        # Add technology tag
        if len(tags) < max_tags and any(t in ['AI', 'AWS', 'Docker'] for t in tags):
            if 'æŠ€è¡“' not in tags:
                tags.append('æŠ€è¡“')
    
    # Ensure unique and limit to max_tags
    unique_tags = list(dict.fromkeys(tags))  # Preserve order while removing duplicates
    return unique_tags[:max_tags]

def update_article_tags(file_path: str, tags: List[str]):
    """Update article file with generated tags"""
    
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Create tags section
    tag_section = f"\n<!--\nGenerated Tags: {', '.join(tags)}\nGenerated at: {datetime.now().isoformat()}\n-->\n"
    
    # Check if tags already exist
    if '<!-- Generated Tags:' in content:
        # Replace existing tags
        content = re.sub(r'<!--\nGenerated Tags:.*?-->\n', tag_section, content, flags=re.DOTALL)
    else:
        # Add tags after title
        title_match = re.search(r'^(# .+\n)', content, re.MULTILINE)
        if title_match:
            content = content.replace(title_match.group(1), title_match.group(1) + tag_section)
        else:
            content = tag_section + content
    
    # Write back to file
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(content)

def process_series_articles(series_name: str):
    """Process all articles in a series"""
    
    series_dir = Path(f"articles/{series_name}")
    if not series_dir.exists():
        print(f"âŒ Series directory not found: {series_dir}")
        return
    
    processed_count = 0
    
    for article_dir in series_dir.iterdir():
        if not article_dir.is_dir() or article_dir.name in ['shared-templates']:
            continue
        
        # Look for article files
        article_files = [
            article_dir / "drafts" / "pages" / "article.md",
            article_dir / "drafts" / "pages" / "main.md",
            article_dir / "drafts" / "pages" / f"{article_dir.name}.md"
        ]
        
        article_file = None
        for f in article_files:
            if f.exists():
                article_file = f
                break
        
        if not article_file:
            print(f"âš ï¸  No article file found in {article_dir.name}")
            continue
        
        print(f"\nğŸ” Analyzing: {article_dir.name}")
        
        # Analyze content
        analysis = analyze_article_content(str(article_file))
        
        # Generate tags
        tags = generate_tags(analysis)
        
        print(f"ğŸ“ Title: {analysis['title']}")
        print(f"ğŸ”§ Tech Terms: {', '.join(analysis['tech_terms'])}")
        print(f"ğŸ¯ Themes: {', '.join(analysis['themes'])}")
        print(f"ğŸ·ï¸  Generated Tags: {', '.join(tags)}")
        
        # Update article with tags
        update_article_tags(str(article_file), tags)
        
        processed_count += 1
    
    print(f"\nâœ… Processed {processed_count} articles in {series_name} series")
    print(f"ğŸ“ Updated files with generated tags")

# Main execution
import sys
from datetime import datetime

if __name__ == "__main__":
    print("ğŸ·ï¸  Article Tag Generator")
    print("=" * 50)
    
    if len(sys.argv) < 2:
        # Interactive mode
        print("Available series:")
        articles_dir = Path("articles")
        if articles_dir.exists():
            series_list = [d.name for d in articles_dir.iterdir() 
                          if d.is_dir() and d.name != 'shared-templates']
            
            for i, series in enumerate(sorted(series_list), 1):
                print(f"{i}. {series}")
            
            try:
                choice = int(input("\nSelect series number: ")) - 1
                if 0 <= choice < len(series_list):
                    series_name = sorted(series_list)[choice]
                else:
                    print("âŒ Invalid selection")
                    sys.exit(1)
            except ValueError:
                print("âŒ Invalid input")
                sys.exit(1)
    else:
        series_name = sys.argv[1]
    
    print(f"\nğŸ¯ Processing series: {series_name}")
    process_series_articles(series_name)
    
    print(f"\nâœ¨ Tag generation complete!")
    print(f"ğŸ’¡ Next step: Run /post-qiita {series_name} to upload with new tags")
```